{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# STB600 Credit Piece Detection - Workbook\n",
        "\n",
        "This notebook demonstrates the image processing pipeline for detecting and decoding colored Starwars Credits.\n",
        "\n",
        "All core functionality is imported from the `stb600_lib` library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Imports & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core dependencies\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Enable inline plotting\n",
        "%matplotlib inline\n",
        "\n",
        "# Import from local library\n",
        "from stb600_lib import (\n",
        "    # IO\n",
        "    load_source_cv2,\n",
        "    # Display\n",
        "    show_image,\n",
        "    annotate_part_result,\n",
        "    draw_labeled_contours_colored,\n",
        "    draw_horizontal_rois_from_boundaries,\n",
        "    resize_to_screen,\n",
        "    make_row,\n",
        "    make_grid,\n",
        "    # Color processing\n",
        "    remove_color_hsv,\n",
        "    detect_piece_color_and_check_size,\n",
        "    detect_color_parts,\n",
        "    # Morphology\n",
        "    binarize_and_invert,\n",
        "    apply_morphological_opening,\n",
        "    apply_morphological_closing,\n",
        "    # Contours\n",
        "    find_and_draw_contours_with_area_limits,\n",
        "    extract_contour_features,\n",
        "    label_contour_by_extent_and_area,\n",
        "    crop_and_align_vertical,\n",
        "    # ROI\n",
        "    split_fixed_horizontal_rois_and_count,\n",
        "    # Decoding\n",
        "    decode_roi_to_number,\n",
        "    compute_total_value_from_rois,\n",
        "    # Transforms\n",
        "    rotate_if_marker_bottom,\n",
        "    # Pipeline\n",
        "    process_piece,\n",
        ")\n",
        "\n",
        "print(\"Library loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Path to test image\n",
        "IMAGE_PATH = r\"C:\\Users\\pablo\\Desktop\\HV\\PEOJECT\\images\\frame_at_8s.png\"\n",
        "\n",
        "# Debug mode - show intermediate results\n",
        "DEBUG = True\n",
        "\n",
        "# Processing parameters (defaults work well for most cases)\n",
        "CONFIG = {\n",
        "    # Green background removal\n",
        "    \"green_color\": \"green\",\n",
        "    \n",
        "    # Main contour detection\n",
        "    \"main_min_area\": 10_000,\n",
        "    \"main_max_area\": 200_000,\n",
        "    \n",
        "    # Color-size thresholds for piece classification\n",
        "    \"small_area_max\": 90_000,\n",
        "    \"medium_area_max\": 130_000,\n",
        "    \n",
        "    # Labeling thresholds for inner parts\n",
        "    \"extent_threshold\": 0.5,\n",
        "    \"label_small_area_max\": 1000,\n",
        "    \"label_medium_area_max\": 2100,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Quick Pipeline (Single Function Call)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load image\n",
        "src_type, img = load_source_cv2(IMAGE_PATH)\n",
        "print(f\"Loaded: {src_type}\")\n",
        "\n",
        "# Run complete pipeline\n",
        "result = process_piece(img, debug=DEBUG, **CONFIG)\n",
        "\n",
        "# Show results\n",
        "print(f\"\\n=== RESULTS ===\")\n",
        "print(f\"Piece color: {result.piece_color}\")\n",
        "print(f\"Size label: {result.size_label}\")\n",
        "print(f\"Consistent: {result.is_consistent}\")\n",
        "print(f\"Total value: {result.total_value}\")\n",
        "print(f\"Decoded digits: {result.decoded_digits}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final annotated result\n",
        "show_image(result.annotated_image, \"Final Result\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Step-by-Step Processing (For Exploration/Debugging)\n",
        "\n",
        "Use these cells to inspect individual steps of the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Load image\n",
        "src_type, img = load_source_cv2(IMAGE_PATH)\n",
        "show_image(img, \"Original Image\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Remove green background\n",
        "no_green, green_mask = remove_color_hsv(img, \"green\")\n",
        "show_image(no_green, \"Without Green Background\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 3: Binarize\n",
        "gray, binary_inv = binarize_and_invert(no_green)\n",
        "show_image(cv2.cvtColor(binary_inv, cv2.COLOR_GRAY2BGR), \"Binary Inverse\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Morphological opening\n",
        "gray_opened = apply_morphological_opening(gray, kernel_size=(5, 5), iterations=1)\n",
        "show_image(cv2.cvtColor(gray_opened, cv2.COLOR_GRAY2BGR), \"After Opening\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 5: Find main contours\n",
        "contours, contour_img = find_and_draw_contours_with_area_limits(\n",
        "    binary_img=gray_opened,\n",
        "    original_bgr=img,\n",
        "    min_area=CONFIG[\"main_min_area\"],\n",
        "    max_area=CONFIG[\"main_max_area\"]\n",
        ")\n",
        "show_image(contour_img, f\"Found {len(contours)} contours\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 6: Get main contour and crop/align\n",
        "main_cnt = max(contours, key=cv2.contourArea)\n",
        "cropped_aligned = crop_and_align_vertical(img, main_cnt)\n",
        "show_image(cropped_aligned, \"Cropped & Aligned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 7: Detect piece color\n",
        "piece_color, size_label, is_consistent, color_counts = detect_piece_color_and_check_size(\n",
        "    img_bgr=img,\n",
        "    contour=main_cnt,\n",
        "    small_area_max=CONFIG[\"small_area_max\"],\n",
        "    medium_area_max=CONFIG[\"medium_area_max\"],\n",
        ")\n",
        "print(f\"Piece color: {piece_color}\")\n",
        "print(f\"Size label: {size_label}\")\n",
        "print(f\"Color consistent: {is_consistent}\")\n",
        "print(f\"Color counts: {color_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 8: Detect internal parts\n",
        "part_contours, part_contour_img, mask_closed = detect_color_parts(\n",
        "    cropped_aligned, piece_color, debug=False\n",
        ")\n",
        "show_image(part_contour_img, f\"Found {len(part_contours)} internal parts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 9: Extract features and label contours\n",
        "features_list = extract_contour_features(part_contours)\n",
        "\n",
        "for f in features_list:\n",
        "    f[\"label\"] = label_contour_by_extent_and_area(\n",
        "        f,\n",
        "        extent_threshold=CONFIG[\"extent_threshold\"],\n",
        "        small_area_max=CONFIG[\"label_small_area_max\"],\n",
        "        medium_area_max=CONFIG[\"label_medium_area_max\"]\n",
        "    )\n",
        "\n",
        "# Display labeled contours\n",
        "labeled_img = draw_labeled_contours_colored(\n",
        "    cropped_aligned, part_contours, features_list,\n",
        "    extent_threshold=CONFIG[\"extent_threshold\"],\n",
        "    small_area_max=CONFIG[\"label_small_area_max\"],\n",
        "    medium_area_max=CONFIG[\"label_medium_area_max\"]\n",
        ")\n",
        "show_image(labeled_img, \"Labeled Contours\")\n",
        "\n",
        "# Print labels\n",
        "for f in features_list:\n",
        "    print(f\"Contour {f['index']}: {f['label']} (area={f['area']:.0f}, extent={f['extent']:.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 10: Compute ROIs and decode values\n",
        "rois, boundaries = split_fixed_horizontal_rois_and_count(\n",
        "    image_shape=cropped_aligned.shape,\n",
        "    features_list=features_list,\n",
        "    piece_color=piece_color,\n",
        ")\n",
        "\n",
        "# Visualize ROIs\n",
        "roi_vis = draw_horizontal_rois_from_boundaries(cropped_aligned, boundaries, alpha=0.3)\n",
        "show_image(roi_vis, \"ROI Visualization\")\n",
        "\n",
        "# Print ROI counts\n",
        "for r in rois:\n",
        "    print(f\"ROI {r['index']} (y: {r['y_start']}-{r['y_end']}): {r['counts']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 11: Decode digits from ROI counts\n",
        "decoded_digits = []\n",
        "for r in rois:\n",
        "    try:\n",
        "        digit = decode_roi_to_number(r[\"counts\"])\n",
        "        decoded_digits.append(digit)\n",
        "        print(f\"ROI {r['index']} -> digit: {digit}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"ROI {r['index']} -> ERROR: {e}\")\n",
        "        decoded_digits.append(None)\n",
        "\n",
        "# Compute total value\n",
        "total_value = compute_total_value_from_rois(decoded_digits, piece_color)\n",
        "print(f\"\\nTotal value: {total_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Batch Processing Multiple Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all test images\n",
        "import os\n",
        "\n",
        "image_folder = r\"C:\\Users\\pablo\\Desktop\\HV\\PEOJECT\\images\"\n",
        "results = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        filepath = os.path.join(image_folder, filename)\n",
        "        print(f\"\\nProcessing: {filename}\")\n",
        "        \n",
        "        try:\n",
        "            _, img = load_source_cv2(filepath)\n",
        "            result = process_piece(img, debug=False)\n",
        "            \n",
        "            results.append({\n",
        "                \"file\": filename,\n",
        "                \"color\": result.piece_color,\n",
        "                \"size\": result.size_label,\n",
        "                \"consistent\": result.is_consistent,\n",
        "                \"value\": result.total_value,\n",
        "            })\n",
        "            print(f\"  -> {result.piece_color} {result.size_label}: value={result.total_value}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"  -> ERROR: {e}\")\n",
        "\n",
        "print(\"\\n=== Summary ===\")\n",
        "for r in results:\n",
        "    print(f\"{r['file']}: {r['color']} {r['size']} = {r['value']} (consistent={r['consistent']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Create Comparison Grid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a grid of annotated results\n",
        "import os\n",
        "\n",
        "image_folder = r\"C:\\Users\\pablo\\Desktop\\HV\\PEOJECT\\images\"\n",
        "annotated_images = []\n",
        "\n",
        "for filename in os.listdir(image_folder):\n",
        "    if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        filepath = os.path.join(image_folder, filename)\n",
        "        try:\n",
        "            _, img = load_source_cv2(filepath)\n",
        "            result = process_piece(img, debug=False)\n",
        "            annotated_images.append(resize_to_screen(result.annotated_image, 400, 400))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "# Create grid (2 images per row)\n",
        "rows = []\n",
        "for i in range(0, len(annotated_images), 2):\n",
        "    row_imgs = annotated_images[i:i+2]\n",
        "    if row_imgs:\n",
        "        rows.append(make_row(row_imgs))\n",
        "\n",
        "if rows:\n",
        "    grid = make_grid(rows)\n",
        "    show_image(grid, \"Results Grid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 7. Interactive GUI Application\n",
        "\n",
        "The library includes an interactive Tkinter GUI for parameter tuning and real-time camera processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GUI Tabs Overview\n",
        "\n",
        "The GUI provides the following interactive tabs for parameter tuning:\n",
        "\n",
        "| Tab | Description |\n",
        "|-----|-------------|\n",
        "| **0) Input** | Load images or toggle camera, select piece color |\n",
        "| **1) Remove green** | Adjust HSV thresholds for background removal |\n",
        "| **2) Binarize** | Adjust binarization threshold |\n",
        "| **3) Opening** | Tune morphological opening kernel and iterations |\n",
        "| **4) Big contours** | Filter contours by area thresholds |\n",
        "| **4b) Cropped main** | View cropped and aligned main piece |\n",
        "| **5) Inner parts** | Detect internal colored parts |\n",
        "| **6) Labeled** | Label parts as marker/small/medium/large + rotation if needed|\n",
        "| **7) ROIs** | Define ROI regions and count parts |\n",
        "\n",
        "Each tab shows real-time results as you adjust the sliders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the GUI module\n",
        "from stb600_lib.gui import run_pipeline_gui, PipelineApp\n",
        "\n",
        "# Launch the interactive pipeline GUI with an initial image\n",
        "# Uncomment and run to start:\n",
        "\n",
        "run_pipeline_gui(use_camera=True)\n",
        "\n",
        "# Or with camera enabled:\n",
        "# run_pipeline_gui(use_camera=True)\n",
        "\n",
        "# Or without any initial image (use \"Load image\" button in GUI):\n",
        "# run_pipeline_gui()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and run the Result Viewer\n",
        "from stb600_lib.gui import run_result_viewer\n",
        "\n",
        "# Launch the result viewer GUI\n",
        "# This opens a window where you can:\n",
        "# - Load an image with the \"Load Image\" button\n",
        "# - The pipeline runs automatically\n",
        "# - See the detected color, size, and VALUE\n",
        "# - Bounding box is drawn around the detected piece\n",
        "\n",
        "run_result_viewer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Video Processor - Tracking & Counting\n",
        "\n",
        "Process videos or live camera feed with object tracking to count unique pieces.\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| **Load Video** | Load a video file (MP4, AVI, MOV) |\n",
        "| **Start Camera** | Use live camera feed |\n",
        "| **Counting Line** | Pieces are counted when crossing this line |\n",
        "| **Object Tracking** | Norfair library tracks pieces across frames |\n",
        "| **Running Total** | Accumulated value of all counted pieces |\n",
        "\n",
        "**Requirements:** `pip install norfair` for object tracking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import and run the Video Processor\n",
        "from stb600_lib.gui import run_video_processor\n",
        "\n",
        "# Launch the video processor GUI\n",
        "# This opens a window where you can:\n",
        "# - Load a video file OR start live camera feed\n",
        "# - Play/Pause/Stop video playback\n",
        "# - Adjust counting line position (H=horizontal, V=vertical)\n",
        "# - See pieces tracked with bounding boxes and IDs\n",
        "# - Pieces are counted when crossing the counting line\n",
        "# - Running total displayed in real-time\n",
        "# - Reset count button to start over\n",
        "\n",
        "run_video_processor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DIAGNOSTIC v2: Use actual config parameters\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "# Load config\n",
        "with open(\"pipeline_config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "shared = config[\"shared\"]\n",
        "rg = shared[\"remove_green\"]\n",
        "op = shared[\"opening\"]\n",
        "\n",
        "print(f\"Config: h_low={rg['h_low']}, h_high={rg['h_high']}\")\n",
        "print(f\"Opening: kernel={op['kernel_size']}, iterations={op['iterations']}\")\n",
        "\n",
        "# Custom green removal using YOUR config parameters\n",
        "def remove_green_with_config(img, h_low, h_high):\n",
        "    \"\"\"Remove green using specific HSV range from config.\"\"\"\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    # Create mask for green\n",
        "    lower = np.array([h_low, 40, 40])\n",
        "    upper = np.array([h_high, 255, 255])\n",
        "    mask = cv2.inRange(hsv, lower, upper)\n",
        "    # Replace green with white\n",
        "    result = img.copy()\n",
        "    result[mask > 0] = [255, 255, 255]\n",
        "    return result, mask\n",
        "\n",
        "from stb600_lib import binarize_and_invert, apply_morphological_opening\n",
        "\n",
        "# Load images\n",
        "img_vertical = cv2.imread(\"images/blue.png\")\n",
        "img_diagonal = cv2.imread(\"images/blue_sideways.png\")\n",
        "\n",
        "def analyze_piece_v2(img, name, h_low, h_high, kernel_size, iterations):\n",
        "    \"\"\"Analyze using actual config parameters.\"\"\"\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    \n",
        "    # Step 1: Remove green with CONFIG parameters\n",
        "    no_green, mask = remove_green_with_config(img, h_low, h_high)\n",
        "    \n",
        "    # Step 2: Binarize\n",
        "    _, binary_raw = binarize_and_invert(no_green, threshold_value=0)\n",
        "    \n",
        "    # Step 3: Morphological opening with CONFIG parameters\n",
        "    binary_opened = apply_morphological_opening(\n",
        "        binary_raw, \n",
        "        kernel_size=(kernel_size, kernel_size), \n",
        "        iterations=iterations\n",
        "    )\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(binary_opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    \n",
        "    if contours:\n",
        "        # Filter to reasonable size (not the whole image)\n",
        "        valid = [c for c in contours if 100000 < cv2.contourArea(c) < 1000000]\n",
        "        if valid:\n",
        "            main = max(valid, key=cv2.contourArea)\n",
        "            area = cv2.contourArea(main)\n",
        "            x, y, w, h = cv2.boundingRect(main)\n",
        "            print(f\"Area: {area:,.0f} px\")\n",
        "            print(f\"Bounding box: {w} x {h} = {w*h:,} px\")\n",
        "            print(f\"Fill ratio: {area/(w*h):.2%}\")\n",
        "            return binary_opened, main, area\n",
        "        else:\n",
        "            print(\"No valid contours found!\")\n",
        "            # Show what WAS found\n",
        "            for i, c in enumerate(contours[:5]):\n",
        "                print(f\"  Contour {i}: area={cv2.contourArea(c):,.0f}\")\n",
        "    \n",
        "    return binary_opened, None, 0\n",
        "\n",
        "# Analyze both\n",
        "b1, c1, area1 = analyze_piece_v2(img_vertical, \"VERTICAL\", rg['h_low'], rg['h_high'], op['kernel_size'], op['iterations'])\n",
        "b2, c2, area2 = analyze_piece_v2(img_diagonal, \"DIAGONAL\", rg['h_low'], rg['h_high'], op['kernel_size'], op['iterations'])\n",
        "\n",
        "# Calculate difference\n",
        "if area1 > 0 and area2 > 0:\n",
        "    diff_pct = abs(area1 - area2) / min(area1, area2) * 100\n",
        "    print(f\"\\n=== COMPARISON ===\")\n",
        "    print(f\"Difference: {abs(area1-area2):,.0f} px ({diff_pct:.1f}%)\")\n",
        "\n",
        "# Show images\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "axes[0].imshow(b1, cmap='gray')\n",
        "axes[0].set_title(f\"Vertical: {area1:,.0f} px\")\n",
        "axes[1].imshow(b2, cmap='gray')\n",
        "axes[1].set_title(f\"Diagonal: {area2:,.0f} px\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
